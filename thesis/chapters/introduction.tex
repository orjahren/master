\chapter{Introduction}

\textbf{Conventional cars} are ubiquitous in society. Whether for freight trafficking or for humans, cars have great flexibility with their ability to go wherever without requiring tailored infrastructure
such as railway tracks. They do, however, have one major weak point --- the human driver. For this
reason, industry and academia have put forward efforts to enhancing cars with \acrfull{ad}
capabilities.
By \textbf{empowering humans} with autonomous vehicles, it is expected that traffic efficiency will
increase and road fatalities will fall.

\textbf{Due to the critical safety situation of manoeuvring a car} In a public setting where other external
actors are present, it is essential that \acrlong{ads} are thoroughly tested before they are
deployed so that they are confirmed to be sufficiently safe and capable of handling the situations in which
they may typically end up.
But due to the complicated nature of the typical \acrshort{ad} operating environment, coming up with
exhaustive system test solutions is near impossible.
For this reason we want a way of testing the system that is capable of pushing the \acrlong{ad} to
its limits such that we can measure its performance and see if it is capable of
handling complex scenarios.

\textbf{Having an existing repository of \acrlong{ad} test cases,} such as
DeepScenario we wish to improve them. \textbf{\acrfull{llms}} have demonstrated
great capabilities of context learning and emergent abilities, which begs
the question of their  applicability for \acrshort{ad} testing.  There are
various methods of testing  \acrlong{ads}. Can these existing test methods be
improved by applying \acrshort{llm} technology to them?

% Yet, testing is \textit{important} for \acrlong{ads}, and text case generation is costly. We
% therefore pose the question: Can \acrshort{llms} be applied for (1) lowering the
% cost of testing, and (2) increasing the thouroughness of \acrlong{ads} testing?
