\chapter{Related work and literature review}\label{chp:relatedWorkAndLitReview}

\epigraph{Learn from the mistakes of others. You can't live long enough to make them all yourself.}{Eleanor Roosevelt}
%\epigraph{The whole is greater than the sum of its parts.}{Aristotle}

This chapter surveys several related works and does a literature review. It contains a selection of
works that are typically related to applying \acrshortpl{llm} specifically or \acrshort{ml} more
generally to \acrshort{ads} simulator scenarios.

\section{Literature review}\label{sec:literatureReview}

This section surveys the current state of the research field with a theoretical
perspective. Applied pieces of work are saved for later, to be surveyed in the
latter part of the chapter.

\subsection{Survey of LLM applications in scenario-based ADS testing}

\citeauthor{surveyLLMScenarioBasedTesting} give an extensive overview of some of the various ways
that \acrshortpl{llm} have been applied to scenario based testing of \acrlongpl{ads}.
The authors classify the various research efforts based on \begin{inparaenum}
    \item how they have employed the \acrshort{llm}, and
    \item to what end
\end{inparaenum}~\cite{surveyLLMScenarioBasedTesting}.
Their survey is continually updated, the last update having been made 2 months before the time of
writing\footnote{I.e. as of September 17th 2025, the last update to their
    \href{https://github.com/ftgTUGraz/LLM4ADSTest}{Github repo} was on July 23rd, 2025. The paper on
    Arxiv was last updated May 22nd 2025.}. This entails a certain overlap with some of the works we
review in \Nref{sec:relatedWork}.
% Not deterred by this, let us look at how they classify the works:

Not deterred by this, let us delve into the survey:
They start by highlighting the trend between the number of \acrshort{llm} surveys, and
\acrshort{ads} surveys -- while the trend was increasing from 2020-23, there was an explision in
\num{2024}, with about \num{200} works concering applying \acrshortpl{llm} for \acrlong{ads}
purposes being published~\cite[p. 1, figure (b)]{surveyLLMScenarioBasedTesting}. Furthermore, the
number of \acrshort{ads} studies has remained steady over the last \num{4}  years, wheras the number
of \acrshort{llm} studies has exploded in popularity~\cite[p. 1, figure
    (a)]{surveyLLMScenarioBasedTesting}. This indicates that a significant amount of the scientific
effort around \acrshortpl{ads} the last year, has been concerned with utilising \acrshortpl{llm}.
% TODO: Er det OK at jeg gjør utledninger som dette? (uten noe referanse)

The article summarizes the field, pulling together various surveys of the
related subfields. Those being \begin{inparaenum}
    \item \acrshort{llm} surveys,
    \item surveys of scenario-based testing,
    \item general cases of \acrshortpl{llm} for \acrshortpl{ads}, and finally
    \item a broader review of surveys of \acrshortpl{llm} being applied for
    \textit{miscellaneous domains}
\end{inparaenum},
for each highlighting their specialized
foci~\cite[2]{surveyLLMScenarioBasedTesting}.

\subsection{LLM4AD}

LLM4AD is a paper that gives a broad overview of \acrshortpl{llm} for \acrlong{ads}. It touches on
several of the various \acrshort{ads} applications where \acrshortpl{llm} are relevant such as
\begin{inparaenum}
    \item language interaction,
    \item contextual understanding,
    \item zero-shot and few shot planning allowing \acrshortpl{llm} to perform tasks they weren't trained
    on, helping with handling edge cases
    \item continuous learning and personalization, and finally
    \item interpretability and trust \end{inparaenum}~\cite[2]{LLM4AD}. Furthermore, the authors
also propose a comprehensive benchmark for evaluating the instruction-following abilities of an
\acrshort{llm} based system in \acrshort{ads} simulation~\cite[1]{LLM4AD}.


\section{Related work}\label{sec:relatedWork}

Having obtained an overview of the current state of the literature, we proceed to surveying several
pieces of applied works. Here, they are categorized broadly with regard to what they do and how the
do it.

There is some overlap between some of the works and several of the categories. A work gets allocated
to the category in which that fits the best with regard to the \emph{focus} of the contribution of the work.

\subsection{ADS scenario generation}

The following works relate to generating \acrshort{ads} test scenarios using traditional
\acrshort{ml} techniques.

\subsubsection{Dataset and toolset -- DeepScenario}\label{sec:deepScenario}

DeepScenario is both a dataset and a toolset aimed at \acrlong{ads} testing~\cite{DeepScenario}. The
principal value proposition of this work lies in recognizing the fact that \begin{inparaenum}
    \item there are an infinite number of possible driving scenarios, and
    \item generating critical driving scenarios is very costly with regard to time costs and
    computational resources\end{inparaenum}~\cite[52]{DeepScenario}. The authors therefore propose
an open driving scenario of more than \num{30000} driving scenarios focusing on \acrshort{ads}
testing~\cite[52]{DeepScenario}. The project utilises traditional machine learning
methodologies, having been performed prior to the broad adaptation of \acrshortpl{llm}.

Its scenarios are intended for the simulator SVL by LG (\Cref{sec:simulatorOverview}).

\subsubsection{Test case specification language -- RTCM}

RTCM is a \acrshort{ads} testing framework that allows the user to utilise natural language for
synthesizing test cases. The authors propose a domain-specific language --- called RTCM, after
\textsc{Restricted Test Case Modelling} --- for specifying test cases. It is based on natural language
and composed of \begin{inparaenum}
    \item an easy-to-use template,
    \item a set of restriction rules, and
    \item keywords \end{inparaenum}~\cite[397]{RTCM}.  Furthermore, they also propose a tool to
take this RTCM source code as input and generating either \begin{inparaenum}
    \item manual, or
    \item automatically \end{inparaenum} executable test cases~\cite[397]{RTCM}. The proposed tools
were evaluated in experiments with industry partners, successfully generating executable test
cases~\cite[397]{RTCM}.

\subsubsection{Generating crash scenarios -- DeepCollision}

\citeauthor{deepCollision} utilise \acrfull{rl} for \acrshort{ads} testing, with the goal of getting
the \acrshort{ads} to \textit{collide}. They used \textit{collision probability} for the loss
function of the \acrlong{rl} algorithm~\cite[384]{deepCollision}. Their experiments included
training 4 DeepCollision models, then using \begin{inparaenum}
    \item random, and
    \item greedy
\end{inparaenum} models for generating a baseline to compare their models with. The results showed
that DeepCollision demonstrated significantly better effectiveness in obtaining collisions than the
baselines. While not specifically focused on \textit{testing}, we recognize that their work is
thematically similar to our project.

\subsection{Utilising LLMs on ADS scenarios}

The remaining works all relate to utilising \acrshortpl{llm} for various purposes related to
\acrshort{ads} scenarios.

\subsubsection{AutoSceneGen}\label{sec:autoSceneGen}

AutoSceneGen is a framework for \acrshort{ads} testing using \acrshortpl{llm},
focusing on the motion planning of \acrlong{ads}~\cite[14539]{autoSceneGen}.
\citeauthor{autoSceneGen} highlights how \acrshortpl{llm} provide opportunities
for efficiently evaluating \acrshort{ads} in a cost-effective
manner~\cite[14539-14540]{autoSceneGen}. They generate a substantial set of synthetic scenarios and
experiment with using \begin{inparaenum}
    \item only synthetic data,
    \item only real-world data, and
    \item a combination of the \num{2} \end{inparaenum} as training data. They find that motion
planners trained with their synthetic data significantly outperforms those trained solely on
real-world data~\cite[14539]{autoSceneGen}.

\subsubsection{LLM-Driven testing of ADS}%\acrshort{ads}}

\citeauthor{LLMDrivenTestingADS24} worked on using \acrshortpl{llm} to for automated test generation
based on free-form textual descriptions in the area of automotive~\cite[173]{LLMDrivenTestingADS24}.
They propose a prototype for this purpose and evaluate their proposal for \acrshort{ads} driving
feature scenarios in Carla. They used the \acrshortpl{llm} GPT-4 and Llama3, finding GPT-4 to
outperform Llama3 for the stated purpose. Their findings include this \acrshort{llm}-powered test
methodology to be more than \num{10} times faster than traditional methodologies while reducing
cognitive load~\cite[173]{LLMDrivenTestingADS24}.
% TODO: Cognitive load -> brain atrophy (sec:llMproblems)

\subsubsection{Requirements All You Need?}

\citeauthor{requirementsAllYouNeed} provide an overview of \acrshortpl{llm} for \acrshort{ads} in
their recent preprint~\citetitle{requirementsAllYouNeed}\footnote{This was submitted to Arxiv on
    2025-05-19.}, focusing on \acrshort{llm}'s abilities for translating abstract requirements extracted
from automotive standards and documents into configuration for Carla (\Cref{sec:simulatorOverview})
simulations~\cite{requirementsAllYouNeed}. Their experiments include employing the
\textit{autonomous emergency braking} system and the sensors of the \acrshort{ads}. Furthermore, they
split the requirements into \num{3} categories: \begin{inparaenum}
    \item vehicle descriptions,
    \item test case pre-conditions, and
    \item test case post-conditions
\end{inparaenum}~\cite{requirementsAllYouNeed}. The preconditions they used included
\begin{inparaenum}
    \item agent placement,
    \item desired agent behaviour, and
    \item weather conditions amongst others\end{inparaenum}, whereas their postconditions reflected
the desired outcomes of the tests, primarily related to the vehicle's
telemetry~\cite{requirementsAllYouNeed}.

\subsubsection{Language Conditioned Traffic Generation}

\citeauthor{languageconditionedtrafficgeneration} look into using \acrshortpl{llm} to generate
specific traffic scenarios. They identify the importance of being able to use simulators to test
\acrshortpl{ads}, and highlight how test scenarios are expensive to
obtain~\cite[1]{languageconditionedtrafficgeneration}. To this end, they propose a tool --
\textsc{LTCGen} which employs the strengths of \acrshortpl{llm} to match a natural language query
with a fitting underlying map\footnote{Map as in a \textit{world} in which a scenario can take
    place.}, and populates this with a \begin{inparaenum}
    \item initial traffic distribution, and
    \item the dynamics of all the vehicles involved in the scene.
\end{inparaenum}
Something to note is that they generate their scenarios, without initially taking the \textit{ego
    vehicle} into account. The ego vehicle of the scene is simply determined as the vehicle that is
in the \textit{centre} of the first
\textit{frame}~\cite[3]{languageconditionedtrafficgeneration}.

\subsubsection{Scenario engineer GPT}

\citeauthor{seGpt} outline a framework for utilising the \acrshort{llm}-backed ChatGPT in order to
generate scenarios. They propose SeGPT -- a scenario generation framework that they found to yield
\textit{significant progress in the domain of scenario generation}~\cite[4422]{seGpt}. They posit
that their prompt engineering ensures that the generated scenarios are authentically diverse and
challenging~\cite[4423]{seGpt}. The focus is primarily on \textit{trajectory
    scenarios}~\cite[4422-4423]{seGpt}.

% TODO: Dette avsittet virker litt malplassert - det virker mer som discussion enn RW
Note how they explicitly mention scenario \textit{generation}. Our approach for this project has a
different angle, with the focus being on modifying \textit{existing} scenarios. More on this in
\Nref{chp:solutionProposal}. The difference between generating a `brand new' scenario with a model
trained on existing scenarios, and modifying an existing scenario seems like a matter of
granularity. These are very similar concepts, only that the enhanced scenario will have more common
DNA whereas the other `new' scenario will consist of a broader range of DNA from its various
underlying scenario corpora.

\subsubsection{LLM driven scenario generation}\label{sec:rwChang24}

\citeauthor{LLMScenarioChang24} also look into using \acrlongpl{llm} to generate \acrshort{ads}
scenarios. They recognize several of the challenges we outline in \Cref{sec:problemDescription}. In
their \citeyear{LLMScenarioChang24} paper, they propose \textsc{LLMScenario}, which is an
\acrshort{llm}-backed framework for both \begin{inparaenum}
    \item scenario generation, and
    \item  evaluation feedback tuning
\end{inparaenum}~\cite[6581]{LLMScenarioChang24}.

They analyse scenarios in order to provide the \acrshort{llm} with a minimum baseline scenario
description, and propose score functions based on both \begin{inparaenum}
    \item reality and
    \item rarity.
\end{inparaenum} Their prompting is based on \acrfull{cot} and a posteriori empirical experience.
Lastly, they tested several \acrlongpl{llm} for their experiments. Their results were positive,
indicating effectiveness for scenario engineering in Industry 5.0~\cite[6581]{LLMScenarioChang24}.
% TODO: Burde finne ut av hva in nomine christi "industry 5.0" er så jeg ikke risikerer å skrive noe
% som ikke gir mening.

\subsubsection{Chat2Scenario}

\citeauthor{chat2Scenario} propose a method for utilising \acrshortpl{llm} to retrieve
\acrshort{ads} scenarios given a natural language query. Their framework synthesizes scenarios from
naturalistic\footnote{Their term. The intended meaning of \textit{naturalistic} is not all clear to
    me.} driving datasets, based on observation real world human driving~\cite[55]{chat2Scenario}, that
it then uses as a database for retrieving the scenario that best matches the user's natural
language query. Furthermore, they employ traditional techniques for asserting the relevance of the
retrieved scenarios, allowing the user to specify a set of \textit{criticality metrics}, of which a
certain threshold must be reached amongst the scenarios that are initially retried by the
\acrshort{llm}, pruning false positives. As a measure to increase the usability of their framework,
they also provide a web-app with an intuitive \acrshort{gui} for both \begin{inparaenum}
    \item operating the tool, and
    \item visualizing the scenarios \end{inparaenum}~\cite[560]{chat2Scenario}.

In order to allow the \acrshort{llm} to determine whether a scenario is relevant under the
provided query, they put forward a method for classifying the various scenarios using traditional
\acrshort{ml} techniques. This classification focuses primarily on highway scenarios and the
activities of other actors in relation to the ego vehicle~\cite[561-562]{chat2Scenario}.

% \textbf{Prompt engineering} <- det ser nesten helt likt ut som et nytt work...

% TODO: Legge inn kryssreferanse til background om prompt engineering? 

The project's prompts are `informed' by the \num{6} \acrlong{oai} guidelines from their prompt
engineering guide\footnote{\url{https://platform.openai.com/docs/guides/prompt-engineering} (URL
    from the paper.)}, ending up with a structured prompt of \num{5} segments. These segments serve to
guide the \acrshort{llm}, delineating its role as an `advanced \acrshort{ai} tool for scenario
analysis, specifically tasked with interpreting driving scenario following a pre-established
classification model'~\cite[562]{chat2Scenario}. They then input the user-provided description of
the scenario they wish to retrieve. Following this, a third segment declares the format for the
\acrshort{llm} response, followed by a prime example of \acrlong{icl}, demonstrating what a
satisfactory fulfilment of the desired format could look like. Lastly they instruct the
\acrshort{llm} to \textit{Remember to analyse carefully and provide the classification as per the
    structure given above}~\cite[563]{chat2Scenario}.
% TODO: Ref siste punkt om "husk å gjøre det riktig" -> kan skrive om dette fenomenet i background
% og så referere tilbake til det.

\subsubsection{Predicting driving comfort in autonomous vehicles using road information and multi-
    head attention models}

The \citeyear{Chen2025} article of \citeauthor{Chen2025}~\cite{Chen2025}, delves into the various
aspects related to predicting driving comfort in autonomous vehicles based on \begin{inparaenum}
    \item available road information, and
    \item multi-head attention models.
\end{inparaenum}
Their principal focus is on driving \emph{comfort}. To this end, they evaluate \acrshortpl{ads} in
light of the \textbf{jerk} metric in various situations. Furthermore, they highlight how a high
complexity in the scenarios can increase the probability of emergency breaking occurring, which is
naturally antithetical to comfort for the \acrshort{ads} operator and their passengers.

\newpage % ser bedre ut

In order to measure this comfort, they rely metrics calculated from data-points from the
\acrshort{ads} system -- jerk and acceleration. This, they use in conjunction with manual human
driving evaluation scores, to compose a new metric, the `driving comfort evaluation score'
(DCES)~\cite[10]{Chen2025}.

Moreover, they use this information to propose a model -- the \acrfull{adcp} model -- for
\emph{predicting} driving comfort from road information~\cite[2]{Chen2025}.