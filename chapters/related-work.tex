\chapter{Related work}\label{sec:relatedWork}

\section{DeepScenario}\label{sec:deepScenario}

DeepScenario is both a dataset and a toolset aimed at \acrlong{ad} testing~\cite{DeepScenario}. The
principal value proposition of this work lies in recognizing the fact that \begin{inparaenum}
    \item there are an infinite number of possible driving scenarios, and
    \item generating critical driving scenarios is very costly with regard to time costs and
    computational resources\end{inparaenum}~\cite[52]{DeepScenario}. The authors therefore propose
an open driving scenario of more than \num{30000} driving scenarios focusing on \acrshort{ad}
testing~\cite[52]{DeepScenario}. The project utilises traditional machine learning
methodologies, having been performed prior to the broad adaptation of \acrshort{llms}.

Its scenarios are intended for the simulator SVL by LG (\Cref{sec:simulatorOverview}).

\section{RTCM}

RTCM is a \acrshort{ad} testing framework that allows the user to utilise natural language for
synthesizing test cases. The authors propose a domain-specific language --- called RTCM, after
\textsc{Restricted Test Case Modelling} --- for specifying test cases. It is based on natural language
and composed of \begin{inparaenum}
    \item an easy-to-use template,
    \item a set of restriction rules, and
    \item keywords \end{inparaenum}~\cite[397]{RTCM}.  Furthermore, they also propose a tool to
take this RTCM source code as input and generating either \begin{inparaenum}
    \item manual, or
    \item automatically \end{inparaenum} executable test cases~\cite[397]{RTCM}. The proposed tools
were evaluated in experiments with industry partners, successfully generating executable test
cases~\cite[397]{RTCM}.

\section{DeepCollision}

\citeauthor{deepCollision} utilise \acrfull{rl} for \acrshort{ad} testing, with the goal of getting
the \acrshort{ad} to \textit{collide}. They used \textit{collision probability} for the loss
function of the \acrlong{rl} algorithm~\cite[384]{deepCollision}. Their experiments included
training 4 DeepCollision models, then using \begin{inparaenum}
    \item random, and
    \item greedy
\end{inparaenum} models for generating a baseline to compare their models with. The results showed
that DeepCollision demonstrated significantly better effectiveness in obtaining collisions than the
baselines. While not specifically focused on \textit{testing}, we recognize that their work is thematically
similar to our envisioned project.

\section{AutoSceneGen}

AutoSceneGen is a framework for \acrshort{ad} testing using \acrshort{llms},
focusing on the motion planning of \acrlong{ads}~\cite[14539]{autoSceneGen}.
\citeauthor{autoSceneGen} highlights how \acrshort{llms} provide opportunities
for efficiently evaluating \acrshort{ads} in a cost-effective
manner~\cite[14539-14540]{autoSceneGen}. They generate a substantial set of synthetic scenarios and
experiment with using \begin{inparaenum}
    \item only synthetic data,
    \item only real-world data, and
    \item a combination of the \num{2} \end{inparaenum} as training data. They find that motion
planners trained with their synthetic data significantly outperforms those trained solely on
real-world data~\cite[14539]{autoSceneGen}.

\section{LLM4AD}

LLM4AD is a paper that gives a broad overview of \acrshort{llms} for \acrlong{ads}. It touches on
several of the various \acrshort{ad} applications where \acrshort{llms} are relevant such as
\begin{inparaenum}
    \item language interaction,
    \item contextual understanding,
    \item zero-shot and few shot planning allowing \acrshort{llms} to perform tasks they weren't trained
    on, helping with handling edge cases
    \item continuous learning and personalization, and finally
    \item interpretability and trust \end{inparaenum}~\cite[2]{LLM4AD}. Furthermore, the authors
also propose a comprehensive benchmark for evaluating the instruction-following abilities of an
\acrshort{llm} based system in \acrshort{ad} simulation~\cite[1]{LLM4AD}.

\section{LLM-Driven testing of \acrshort{ad}}

\citeauthor{LLMDrivenTestingADS24} worked on using \acrshort{llms} to for automated test generation
based on free-form textual descriptions in the area of automotive~\cite[173]{LLMDrivenTestingADS24}.
They propose a prototype for this purpose and evaluate their proposal for \acrshort{ad} driving
feature scenarios in Carla. They used the \acrshort{llms} GPT-4 and Llama3, finding GPT-4 to
outperform Llama3 for the stated purpose. Their findings include this \acrshort{llm}-powered test
methodology to be more than \num{10} times faster than traditional methodologies while reducing
cognitive load~\cite[173]{LLMDrivenTestingADS24}.
% TODO: Cognitive load -> brain atrophy (sec:llMproblems)

\section{Requirements All You Need?}

\citeauthor{requirementsAllYouNeed} provide an overview of \acrshort{llms} for \acrshort{ads} in
their recent preprint~\citetitle{requirementsAllYouNeed}\footnote{This was submitted to Arxiv on
    2025-05-19.}, focusing on \acrshort{llm}'s abilities for translating abstract requirements extracted
from automotive standards and documents into configuration for Carla (\Cref{sec:simulatorOverview})
simulations~\cite{requirementsAllYouNeed}. Their experiments include employing the
\textit{autonomous emergency braking} system and the sensors of the \acrshort{ad}. Furthermore, they
split the requirements into \num{3} categories: \begin{inparaenum}
    \item vehicle descriptions,
    \item test case pre-conditions, and
    \item test case post-conditions (\Nref{sec:testingConditions})
\end{inparaenum}~\cite{requirementsAllYouNeed}. The preconditions they used included
\begin{inparaenum}
    \item agent placement,
    \item desired agent behaviour, and
    \item weather conditions amongst others\end{inparaenum}, whereas their postconditions reflected
the desired outcomes of the tests, primarily related to the vehicle's
telemetry~\cite{requirementsAllYouNeed}.

\section{Language Conditioned Traffic Generation}

\citeauthor{languageconditionedtrafficgeneration} look into using \acrshort{llms} to generate
specific traffic scenarios. They identify the importance of being able to use simulators to test
\acrshort{ads}, and highlight how test scenarios are expensieve to
obtain~\cite[1]{languageconditionedtrafficgeneration}. To this end, they propose a a tool \em
\textsc{LTCGen} which employs the strengths of \acrshort{llms} to match a natural language query
with a fitting underlying map\footnote{Map as in a \textit{world} in which a scenario can take
    place}, and populates this with a \begin{inparaenum}
    \item initial traffic distribiution, and
    \item the dynamics of all the vehicles involved in the scene.
\end{inparaenum}
Something to note is that they generate their scenarios, without initially taking the \textit{ego
    vehicle} into account. The ego vehicle of the scene is simply determined as the vehicle that is in
the \textit{center} of the first \textit{frame}~\cite[3]{languageconditionedtrafficgeneration}.