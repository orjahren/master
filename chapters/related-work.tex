\chapter{Related work}\label{sec:relatedWork}

\epigraph{Learn from the mistakes of others. You can't live long enough to make them all yourself.}{Eleanor Roosevelt}

This chapter surveys several related works. It contains a selection of works that are typically
related to applying \acrshortpl{llm} specifically or \acrshort{ml} more generally to \acrshort{ads}
simulator scenarios.

\section{DeepScenario}\label{sec:deepScenario}

DeepScenario is both a dataset and a toolset aimed at \acrlong{ads} testing~\cite{DeepScenario}. The
principal value proposition of this work lies in recognizing the fact that \begin{inparaenum}
  \item there are an infinite number of possible driving scenarios, and
  \item generating critical driving scenarios is very costly with regard to time costs and
  computational resources\end{inparaenum}~\cite[52]{DeepScenario}. The authors therefore propose
an open driving scenario of more than \num{30000} driving scenarios focusing on \acrshort{ads}
testing~\cite[52]{DeepScenario}. The project utilises traditional machine learning
methodologies, having been performed prior to the broad adaptation of \acrshortpl{llm}.

Its scenarios are intended for the simulator SVL by LG (\Cref{sec:simulatorOverview}).

\section{RTCM}

RTCM is a \acrshort{ads} testing framework that allows the user to utilise natural language for
synthesizing test cases. The authors propose a domain-specific language --- called RTCM, after
\textsc{Restricted Test Case Modelling} --- for specifying test cases. It is based on natural language
and composed of \begin{inparaenum}
  \item an easy-to-use template,
  \item a set of restriction rules, and
  \item keywords \end{inparaenum}~\cite[397]{RTCM}.  Furthermore, they also propose a tool to
take this RTCM source code as input and generating either \begin{inparaenum}
  \item manual, or
  \item automatically \end{inparaenum} executable test cases~\cite[397]{RTCM}. The proposed tools
were evaluated in experiments with industry partners, successfully generating executable test
cases~\cite[397]{RTCM}.

\section{DeepCollision}

\citeauthor{deepCollision} utilise \acrfull{rl} for \acrshort{ads} testing, with the goal of getting
the \acrshort{ads} to \textit{collide}. They used \textit{collision probability} for the loss
function of the \acrlong{rl} algorithm~\cite[384]{deepCollision}. Their experiments included
training 4 DeepCollision models, then using \begin{inparaenum}
  \item random, and
  \item greedy
\end{inparaenum} models for generating a baseline to compare their models with. The results showed
that DeepCollision demonstrated significantly better effectiveness in obtaining collisions than the
baselines. While not specifically focused on \textit{testing}, we recognize that their work is thematically
similar to our envisioned project.

\section{AutoSceneGen}\label{sec:autoSceneGen}

AutoSceneGen is a framework for \acrshort{ads} testing using \acrshortpl{llm},
focusing on the motion planning of \acrlong{ads}~\cite[14539]{autoSceneGen}.
\citeauthor{autoSceneGen} highlights how \acrshortpl{llm} provide opportunities
for efficiently evaluating \acrshort{ads} in a cost-effective
manner~\cite[14539-14540]{autoSceneGen}. They generate a substantial set of synthetic scenarios and
experiment with using \begin{inparaenum}
  \item only synthetic data,
  \item only real-world data, and
  \item a combination of the \num{2} \end{inparaenum} as training data. They find that motion
planners trained with their synthetic data significantly outperforms those trained solely on
real-world data~\cite[14539]{autoSceneGen}.

\section{LLM4AD}

LLM4AD is a paper that gives a broad overview of \acrshortpl{llm} for \acrlong{ads}. It touches on
several of the various \acrshort{ads} applications where \acrshortpl{llm} are relevant such as
\begin{inparaenum}
  \item language interaction,
  \item contextual understanding,
  \item zero-shot and few shot planning allowing \acrshortpl{llm} to perform tasks they weren't trained
  on, helping with handling edge cases
  \item continuous learning and personalization, and finally
  \item interpretability and trust \end{inparaenum}~\cite[2]{LLM4AD}. Furthermore, the authors
also propose a comprehensive benchmark for evaluating the instruction-following abilities of an
\acrshort{llm} based system in \acrshort{ads} simulation~\cite[1]{LLM4AD}.

\section{LLM-Driven testing of \acrshort{ads}}

\citeauthor{LLMDrivenTestingADS24} worked on using \acrshortpl{llm} to for automated test generation
based on free-form textual descriptions in the area of automotive~\cite[173]{LLMDrivenTestingADS24}.
They propose a prototype for this purpose and evaluate their proposal for \acrshort{ads} driving
feature scenarios in Carla. They used the \acrshortpl{llm} GPT-4 and Llama3, finding GPT-4 to
outperform Llama3 for the stated purpose. Their findings include this \acrshort{llm}-powered test
methodology to be more than \num{10} times faster than traditional methodologies while reducing
cognitive load~\cite[173]{LLMDrivenTestingADS24}.
% TODO: Cognitive load -> brain atrophy (sec:llMproblems)

\section{Requirements All You Need?}

\citeauthor{requirementsAllYouNeed} provide an overview of \acrshortpl{llm} for \acrshort{ads} in
their recent preprint~\citetitle{requirementsAllYouNeed}\footnote{This was submitted to Arxiv on
  2025-05-19.}, focusing on \acrshort{llm}'s abilities for translating abstract requirements extracted
from automotive standards and documents into configuration for Carla (\Cref{sec:simulatorOverview})
simulations~\cite{requirementsAllYouNeed}. Their experiments include employing the
\textit{autonomous emergency braking} system and the sensors of the \acrshort{ads}. Furthermore, they
split the requirements into \num{3} categories: \begin{inparaenum}
  \item vehicle descriptions,
  \item test case pre-conditions, and
  \item test case post-conditions (\Nref{sec:testingConditions})
\end{inparaenum}~\cite{requirementsAllYouNeed}. The preconditions they used included
\begin{inparaenum}
  \item agent placement,
  \item desired agent behaviour, and
  \item weather conditions amongst others\end{inparaenum}, whereas their postconditions reflected
the desired outcomes of the tests, primarily related to the vehicle's
telemetry~\cite{requirementsAllYouNeed}.

\section{Language Conditioned Traffic Generation}

\citeauthor{languageconditionedtrafficgeneration} look into using \acrshortpl{llm} to generate
specific traffic scenarios. They identify the importance of being able to use simulators to test
\acrshortpl{ads}, and highlight how test scenarios are expensieve to
obtain~\cite[1]{languageconditionedtrafficgeneration}. To this end, they propose a tool --
\textsc{LTCGen} which employs the strengths of \acrshortpl{llm} to match a natural language query
with a fitting underlying map\footnote{Map as in a \textit{world} in which a scenario can take
  place.}, and populates this with a \begin{inparaenum}
  \item initial traffic distribiution, and
  \item the dynamics of all the vehicles involved in the scene.
\end{inparaenum}
Something to note is that they generate their scenarios, without initially taking the \textit{ego
  vehicle} into account. The ego vehicle of the scene is simply determined as the vehicle that is
in the \textit{center} of the first
\textit{frame}~\cite[3]{languageconditionedtrafficgeneration}.

\section{Scenario engineer GPT}

\citeauthor{seGpt} outline a framework for utilising the \acrshort{llm}-backed ChatGPT in order to
generate scenarios. They propose SeGPT -- a scenario generation framework that they found to yield
\textit{significant progress in the domain of scenario generation}~\cite[4422]{seGpt}. They posit
that their prompt engineering ensures that the generated scenarios are authentically diverse and
challenging~\cite[4423]{seGpt}. The focus is primarily on \textit{trajectory
  scenarios}~\cite[4422-4423]{seGpt}.

% TODO: Dette avsittet virker litt malplassert - det virker mer som discussion enn RW
Note how they explicitly mention scenario \textit{generation}. Our approach for this project has a
different angle, with the focus being on modifying \textit{existing} scenarios. More on this in
\Nref{sec:solutionProposal}. The difference between generating a `brand new' scenario with a model
trained on exisiting scenarios, and modifying an existing scenario seems like a matter of
granularity. These are very similar concepts, only that the enhanced scenario will have more common
DNA whereas the other `new' scenario will consist of a broader range of DNA from its various
underlying scenario corpora.

\section{LLM driven scenario generation}

\citeauthor{LLMScenarioChang24} also look into using \acrlongpl{llm} to generate \acrshort{ads}
scenarios. They recognize several of the challenges we outline in \Cref{sec:problemDescription}. In
their \citeyear{LLMScenarioChang24} paper, they propose \textsc{LLMScenario}, which is an
\acrshort{llm}-backed framework for both \begin{inparaenum}
  \item scenario generation, and
  \item  evaluation feedback tuning
\end{inparaenum}~\cite[6581]{LLMScenarioChang24}.

They analyze scenarios in order to provide the \acrshort{llm} with a minimum baseline scenario
description, and propose score functions based on both \begin{inparaenum}
  \item reality and
  \item rarity.
\end{inparaenum} Their prompting is based on \acrfull{cot} and a posteriori emperical experience.
Lastly, they tested several \acrlongpl{llm} for their experiments. Their results were positive,
indicating effectiveness for scenaro engineering in Industry 5.0~\cite[6581]{LLMScenarioChang24}.
% TODO: Burde finne ut av hva in nomine christi "industry 5.0" er så jeg ikke risikerer å skrive noe
% som ikke gir mening.

\section{Chat2Scenario}

\citeauthor{chat2Scenario} propose a method for utilising \acrshortpl{llm} to retrieve
\acrshort{ads} scenarios given a natural language query. Their framework synthesizes scenarios from
naturalistic\footnote{Their term. The intended meaning of \textit{naturalistic} is not all clar to
  me.} driving datasets, based on observation real world human driving~\cite[55]{chat2Scenario}, that
it then uses as a database for retrieveing the scenario that best matches the user's natural
language query. Furthermore, they employ traditional techniques for asserting the relevance of the
retrieved scenarios, allowing the user to specify a set of \textit{criticality metrics}, of which a
certain threshold must be reached amongst the scenarios that are initalliy retried by the
\acrshort{llm}, pruning false positives. As a measure to increase the usability of their framework,
they also provide a webapp with an intuitive \acrshort{gui} for both \begin{inparaenum}
  \item operating the tool, and
  \item visualizing the scenarios \end{inparaenum}~\cite[560]{chat2Scenario}.

In order to allow the \acrshort{llm} to determine whether a scenario is relevant under the
provided query, they put forward a method for classifying the various scenarios using traditional
\acrshort{ml} techniques. This classification focuses primarily on highway scenarios and the
activities of other actors in relation to the ego vehicle~\cite[561-562]{chat2Scenario}.

\subsubsection*{Prompt engineering}

% TODO: Legge inn kryssreferanse til background om prompt engineering? 

The project's prompts are `informed' by the \num{6} \acrlong{oai} guidelines from their prompt
engineering guide\footnote{\url{https://platform.openai.com/docs/guides/prompt-engineering} (URL
  from the paper.)}, ending up with a structured prompt of \num{5} segments. These segments serve to
guide the \acrshort{llm}, delineating its role as an `advanced \acrshort{ai} tool for scenario
analysis, specifically tasked with interpreting driving scenario following a pre-established
classification model'~\cite[562]{chat2Scenario}. They then input the user-provided description of
the scenario they wish to retrieve. Following this, a third segment declares the format for the
\acrshort{llm} response, followed by a prime example of \acrlong{icl}, demonstrating what a
satisfactory fulfillment of the desired format could look like. Lastly they instruct the
\acrshort{llm} to \textit{Remember to analyze carefully and provide the classification as per the
  structure given above}~\cite[563]{chat2Scenario}.
% TODO: Ref siste punkt om "husk å gjøre det riktig" -> kan skrive om dette fenomenet i background
% og så referere tilbake til det.

\section{Predicting driving comfort in autonomous vehicles using road information and multi- head
  attention models}

The \citeyear{Chen2025} article of \citeauthor{Chen2025}~\cite{Chen2025}, delves into the various
aspects related to predicting driving comfort in autonomous vehicles based on \begin{inparaenum}
  \item available road information, and
  \item multi-head attention models.
\end{inparaenum}
Their principal focus is on driving \emph{comfort}. To this end, they evaluate \acrshortpl{ads} in
light of the \textbf{jerk} metric in various situations. Furthermore, they highlight how a high
complexity in the scenarios can increase the probability of emergency breaking occurring, which is
naturally antithetical to comfort for the \acrshort{ads} operator and their passengers.

In order to measure this comfort, they rely metrics calculated from datapoints from the
\acrshort{ads} system -- jerk and acceleration. This, they use in conjunction with manual human
driving evaluation scores, to compose a new metric, the `driving comfort evaluation score'
(DCES)~\cite[10]{Chen2025}.

Moreover, they use this information to propose a model -- the \acrfull{adcp} model -- for
\emph{predicting} driving comfort from road information~\cite[2]{Chen2025}.