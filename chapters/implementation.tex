
\chapter{Implementation architecture}
\chapter{Implementation details 1 - Thor}

Rest API - running test cases - Thor
“Fast API”, Python
POST a test case to the API. It will be ran on the ‘server’
RabbitMQ for listening for finished test cases? So that the client knows it can fetch the results?
Will need UUID for test cases so the correct result can be fetched after it has been ran
Need to store these somewhere. NoSQL database?
This component should also accumulate results.
Huge TODO: What metric are these results?
Should be containerised (Docker/Podman)

\chapter{Implementation details 2 - Odin}\label{sec:odinImplementation}

Rest API - performing LLM enhancement - Odin
“Fast API”, Python
Take a base test case as body
Have some prompt repository
Apply prompts with LLMs
Must integrate with LLM. Either locally (Ollama) or remote (some API)
Look into good LLM agnostic transition layer. E.g. Aisuite
https://github.com/andrewyng/aisuite
Should use same UUIDs as outlined above, but suffixed with e.g. “pure” and “tainted”
Containerized. Docker compose?

\chapter{Implementation details 3 - Loki}

Client - orchestrating the process - Loki
Fetch available test cases from Thor? Select what/which are to be used
Store results clientside? Separate database for this?