\chapter{Experiment methodology}\label{chp:experiments}

\epigraph{The torment of precautions often exceeds the dangers to be avoided. It is sometimes better to abandon one's self to destiny.}{Napol√©on}

This chapter will describe the experimentation that has been done with the implemented solution
proposal (\Cref{chp:solutionProposal}), in anticipation of analysing the \Nref{chp:results}.

\section{Prompts}

Prompting is our principal way of interfacing with the \acrshort{llm}. For this reason, our results
rely on \begin{inparaenum}
    \item good, and
    \item fitting prompts
\end{inparaenum}. Without this all is lost.

We therefore propose several prompting strategies, taking after related research
(\Nref{chp:relatedWork}).

Prompts were determined by trial and error in an iterative manner, in
conjunction with GitHub Copilot. They are all descendant of listing
\ref{lst:firstPrompt}, each subsequent iteration improving on the last based on
what worked or did not worked when assessing the output.
Due to a technical detail of the
\hefe~implementation (\Nref{sec:odinImplementation}), the datatype of the prompt is
a lambda function that takes the raw scenario represented as a string and then
inserts it into the prompt in runtime. This is represented by the curly braces
on line \num{3} in listing~\ref{lst:firstPrompt}.

\begin{lstlisting}[caption={The first prompt.}, label={lst:firstPrompt}, language={Python}]
lambda python_carla_scenario_raw: f"""
1 - Context: We are working with a driving simulation environment for the Carla simulator.
2 - Task: Decrease the driveability of the scenario by enhancing it with more details and complexity.
3 - Input: {python_carla_scenario_raw}
4 - Output: An enhanced version of the scenario description with additional
details and complexity, still in Python carla scenario format.
""",
\end{lstlisting}

\section{Finding a suitable LLM}

As we learnt in \Cref{sec:llmJungle}, there are several \acrshortpl{llm} extant. We should
experiment with various different \acrshortpl{llm} to maximize our chance of testing with a `good'
\acrshort{llm} that goes well with our stated purpose.

The experiments were first carried out using a locally hosted \num{7.2}B parameter Mistral model.
This model is interesting in that it has been shown to outperform significantly larger models
across various benchmarks\footnote{\url{https://ollama.com/library/mistral}}. Due to its small
nature, however, these initial results were not that promising. Later, in order to obtain better
results, the Gemini model \texttt{Gemini 2.5 flash} running on Google's infrastructure was used.
This is a mid-size multimodal model that supports up to 1 million tokens, released in June of 2025,
with support for thinking and long
contexts\footnote{\url{https://deepmind.google/models/gemini/flash/}}.

All data in the \Nref{chp:results} chapter, are obtained using the Gemini model.

\section{Metrics}

The way the Carla simulator works, one simulator run can be analysed post factum. The entire
scenario execution is stored in a Carla-specific binary format. This binary file can then later be
analysed, extracting various metrics from one run. This saves time not having to run the simulator
more than necessary, and allows for reproducing the metric calculations from the original underlying
binary log file.

Due to the immense file size of these logs\footnote{Keep in mind that they track all actors in the
    scene over time.}, publishing all our raw files is not feasible.
