\chapter{Experiment methodology}\label{sec:experiments}

\epigraph{The torment of precautions often exceeds the dangers to be avoided. It is sometimes better to abandon one's self to destiny.}{Napol√©on}

This chapter will describe the experimentation that has been done with the implemented solution
proposal (\Cref{sec:solutionProposal}), in anticipation of analzying the \Nref{sec:results}.

\section{Prompts}

Prompting is our principal way of interfacing with the \acrshort{llm}. For this reason, our results
rely on \begin{inparaenum}
    \item good, and
    \item fitting prompts
\end{inparaenum}. Without this all is lost.

We therefore propose several prompting strategies, taking after related research
(\Nref{sec:relatedWork}).

Prompts were determined by trial and error in an iterative manner, in
conjunction with Github Copoilot. They are all descendant of listing
\ref{lst:firstPrompt}, each subsequent iteration improving on the last based on
what worked or did not worked when assessing the output.
Due to a techical detail of the
\hefe~implementation (\Nref{sec:odinImplementation}), the datype of the prompt is
a lambda function that takes the raw scenario represented as a string and then
inserts it into the prompt in runtime. This is represented by the curly braces
on line \num{3} in listing~\ref{lst:firstPrompt}.

\begin{lstlisting}[caption={The first prompt.}, label={lst:firstPrompt}, language={Python}]
lambda python_carla_scenario_raw: f"""
1 - Context: We are working with a driving simulation environment for the Carla simulator.
2 - Task: Decrease the driveability of the scenario by enhancing it with more details and complexity.
3 - Input: {python_carla_scenario_raw}
4 - Output: An enhanced version of the scenario description with additional
details and complexity, still in Python carla scenario format.
""",
\end{lstlisting}

\section{Trying different \acrshortpl{llm}}

As we learnt in \Cref{sec:llmJungle}, there are several \acrshortpl{llm} extant. We should
experiment with various different \acrshortpl{llm} to maximize our chance of testing with a `good'
\acrshort{llm} that goes well with our stated purpose.

The results were first carried out using a locally hosted \num{7.2}B parameter
Mistral model. Later, a Gemini model running on Google's infrastrucutre was used.

\section{Metrics}

The way the Carla simulator works, one simulator run can be analyzed post factum. The entire
scenario execution is stored in a Carla-specific binary format. This binary file can then later be
analyzed, extracting various metrics from one run. This saves time not having to run the simulator
more than necessary, and allows for reproducing the metric calculations from the original underlying
binary log file.

Due to the immense file size of these logs\footnote{Keep in mind that they track all actors in the
    scene over time.}, publishing all our raw files is not feasible.
