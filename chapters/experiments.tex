\chapter{Experiment methodology}\label{chp:experiments}

% FORMAT PÅ CHPTRS Experiments-Results-Discussion:

% chapter 6 can be about how you get the results, how you analyze and structure the results 
% and then the results chapter is just listing the results. Which makes the chapters reflect each
% other

% in the discussion again follow the same format to a agree, maybe combine the results from different parts. Then it is easer to follow and make conclusions


\epigraph{The torment of precautions often exceeds the dangers to be avoided. It is sometimes better to abandon one's self to destiny.}{Napoléon}

This chapter will describe the experimentation that has been done with the implemented solution
proposal (\Cref{chp:solutionProposal}), describing the methodological process that was undertaken in
order to obtain the \Nref{chp:results}. This chapter lays the groundwork for presenting them
succinctly with their relevant context in \Cref{chp:results} and then analysing them in
\Cref{chp:discussion}.


\section{ADS-related aspects}

This section surveys \acrshort{ads}-related aspects from the experimentation,
detailing the experimentation related to scenarios and metrics.

\subsection{Scenarios}

We do naturally have to walk before we can run. For this reason, the tool will initially be
tested on simple test scenarios provided by people behind the Carla simulator. When we have verified
that the project is sufficiently working for its stated purpose, we can scale up the activities to
other datasets. Several are presented in \Nref{sec:relatedWork}. The concept of applying
\acrshortpl{llm} to \acrshort{ads} scenarios is quite universal in nature and is eligible for
application for virtually \emph{all} datasets.

The experimentation for developing and evaluating the \hefe~tool focused on the
scenarios \texttt{Accident}, \texttt{CutIn}, \texttt{NoSignalJunctionCrossing}
and \texttt{FollowLeadingVehicle}. 


\subsection{Metrics}\label{sec:experimentsMetrics}

The goal of this project is to decrease the driveability of the scenario such that we are able to
`flag' potential issues in the \acrshort{ads}. As `driveability' is a very broad concept (see
\Nref{sec:adsDrivability}), there are several relevant metrics and datapoints that can potentially
be used.

For this project, due to its broad scope, a similarly broad metric will be used for indicating that
an experiment has yielded a meaningful result -- jerk. As outlined in \Nref{sec:adsMetrics}, jerk
has been shown to be related to several factors contributing to driveability.

Again owning to the broad scope, exact jerk \emph{numbers} are not relevant -- for our purposes, it
suffices to have a binary relation to the jerk being either \begin{inparaenum}
    \item more or less unchanged\footnote{Keep in mind that \acrshort{ads} motion planners are
        indeterministic}, or
    \item worsened.
\end{inparaenum} If the driveability has decreased, we will have found a result.

Lastly, it's worth noting that qualitative analysis by intuition from visually inspecting the
scenarios is also useful here. If the \acrshort{llm} has introduced an obstacle in the course of the
road where the \acrshort{ads} is to drive, we intuitively know that this enhanced scenario is more
complex and less drivable -- which also indicates a result.


\section{LLM-related aspects}

The last section of this chapter explores aspects related to the \acrshort{llm}
usage in the experiments, detailing the usage of prompts and determining what
\acrshort{llm} is to be used, along with some preliminary results.

\subsection{Prompts}

Prompting is our principal way of interfacing with the \acrshort{llm}. For this reason, our results
depend on \begin{inparaenum}
    \item good, and
    \item fitting prompts
\end{inparaenum}. Without this, we won't get far.

We therefore propose several prompting strategies, taking after related research
(\Nref{sec:relatedWork}).

Prompts were determined by trial and error in an iterative manner, in
conjunction with GitHub Copilot. They are all descendant of listing
\ref{lst:firstPrompt}, each subsequent iteration improving on the last based on
what worked or did not worked when assessing the output.
Due to a technical detail of the
\hefe~implementation (\Nref{sec:odinImplementation}), the datatype of the prompt is
a lambda function that takes the raw scenario represented as a string and then
inserts it into the prompt in runtime. This is represented by the curly braces
on line \num{3} in listing~\ref{lst:firstPrompt}.

\begin{lstlisting}[caption={The first prompt.}, label={lst:firstPrompt}, language={Python}]
lambda python_carla_scenario_raw: f"""
1 - Context: We are working with a driving simulation environment for the Carla simulator.
2 - Task: Decrease the driveability of the scenario by enhancing it with more details and complexity.
3 - Input: {python_carla_scenario_raw}
4 - Output: An enhanced version of the scenario description with additional
details and complexity, still in Python carla scenario format.
""",
\end{lstlisting}


\subsection{Finding a suitable LLM}\label{sec:llmExperimentation}

As we learnt in \Cref{sec:llmJungle}, there are several \acrshortpl{llm} extant. We should
experiment with various different \acrshortpl{llm} to maximize our chance of testing with a `good'
\acrshort{llm} that goes well with our stated purpose.

The experiments were first carried out using a locally hosted \num{7.2}B parameter Mistral model.
This model is interesting in that it has been shown to outperform significantly larger models
across various benchmarks\footnote{\url{https://ollama.com/library/mistral}}.
Similarly, the Gemini model \texttt{Gemini 2.5 flash} running on Google's infrastructure was used.
This is a mid-size multimodal model that supports up to 1 million tokens, released in June of 2025,
with support for thinking and long
contexts\footnote{\url{https://deepmind.google/models/gemini/flash/}}.

All data presented in the \Nref{chp:results} chapter, are obtained using the Gemini model.


\subsection{Output of the LLM -- general overview}

The following reviews \begin{inparaenum}
    \item what works well,
    \item why it works, and
    \item what does \emph{not} work and
    \item why this is.
\end{inparaenum}

Depending on the prompt, our results show that it is very possible to get reasonable-looking Python
out of the \acrshort{llm}. One somewhat cumbersome detail is their bent to mark the code as specific
syntax, the entire \acrshort{llm} response being a Markdown-formatted code block indicating both
that the output \emph{is} code, and what language it is in,to the first and last line of the output
(Listing~\ref{lst:llmOutputMarkdown}). Several leaked \acrshort{llm} system prompts corroborate this
behaviour\footnote{See e.g.\url{https://github.com/search?q=repo\%3Ajujumilk3\%2Fleaked-system-prompts\%20markdown&type=code}.}.

% \begin{lstlisting}[language=Markdown]
\begin{lstlisting}[caption={LLM-generated Python code with Markdown syntax. The bracketed part on line 3 has been added for demonstration purposes, removing the actual code for brevity.}, label={lst:llmOutputMarkdown}]
```python

[ scenario code ]

```
\end{lstlisting}

Upon removing these syntactic artefacts, we can go ahead with executing
the scenario. As previously mentioned, not all enhanced scenarios immediately work with the Carla
simulator. This primarily comes down to \begin{inparaenum}
    \item hallucination of Python code, and
    \item Carla problems, along with the aforementioned
    \item markdown-formatted output.
\end{inparaenum}

Something worth noting is that the \acrshort{llm} demonstrates a promising
ability to explain back to the user \emph{how} it enhanced the scenario, e.g. in
the form of bullets in a docstring of the output code (see listing \ref{lst:llmOutputExplenation}).

% NOTE: Dette eksempelet er hentet fra CiE-6.
\begin{lstlisting}[caption={Head of an \acrshort{llm}-enhanced scenario, highlighting how the \acrshort{llm} can add an explenation of how it enhanced the scenario.}, label={lst:llmOutputExplenation}, language={Python}]
#!/usr/bin/env python

# Copyright (c) 2019-2020 Intel Corporation
#
# This work is licensed under the terms of the MIT license.
# For a copy, see <https://opensource.org/licenses/MIT>.

"""
Cut in scenario:

The scenario realizes a driving behavior on the highway.
The user-controlled ego vehicle is driving straight and keeping its velocity at a constant level.
Another car is cutting just in front, coming from left or right lane.

The ego vehicle may need to brake to avoid a collision.

Enhanced scenario:
- Increased background traffic with varying speeds to create a more crowded environment.
- Challenging weather conditions (heavy rain, fog, strong winds) to reduce visibility and grip.
- Nighttime setting to further decrease visibility.
- Randomization of speeds and trigger distances for increased unpredictability.
"""
[...]
\end{lstlisting}


\subsection{Hallucinations in the enhanced scenarios}\label{sec:resultsHallucinations}

The \acrshort{llm} typically seems to be on the right track, outlining something
that \emph{sounds} like a good approach to satisfying our prompt of decreasing
the driveability of the scenario. But in practice, it will often hallucinate
methods that don't exist, or use terms and phrasing that are not valid keywords
in the Carla specification. This is in line with what was found by e.g.
\citeauthor{autoSceneGen}~\cite[14542]{autoSceneGen} (See \Nref{sec:autoSceneGen} in
\Nref*{sec:relatedWork}).

% TODO: Legge til ekesempler her
% TODO: Er vi sikre på at dette handler om spesifikt hallusinering og ikke noe annet?
\subsubsection{Non-existing methods}

As mentioned, the \acrshort{llm} seems to have the right idea of what it can do
to achieve the stated goal. But the way that it goes about obtaining it, does
not always work. The enhanced scenario code will often call methods that don't
exist. This leads to a runtime exception in the scenario runner when executing
the enhanced scenario.

% TODO: Legge til ekesempler her
% TODO: Er vi sikre på at dette handler om spesifikt hallusinering og ikke noe annet?
\subsubsection{Non-existing arguments}

In a similar vein to the non-existing methods, non-existing \emph{arguments}
were also shown to appear. The \acrshort{llm} could simply call methods that
were already being used, with additional arguments that made semantic sense,
but that were not a part of the function definition. This also causes runtime
exceptions in the scenario runner.

% TODO: Burde refereree / kildeføre / vise til noe forankring for disse keyword-eksemplene.
\subsubsection{Illegal property keywords}

Another trend we observed was the usage of various keywords that simply don't
exist in the Carla repertoire. Where Carla would recognize the word `snowstorm',
the \acrfull{llm} could propose using the word `blizzard'.
