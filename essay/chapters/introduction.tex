\section*{Introduction}

\paragraph{Conventional cars} are ubiquitous in society. Be it either for trafficking freight or humans, cars
affort great flexibility with their ability to go wherever without requiring tailored infrastructure
such as railway tracks. They do however have one major weak point - the human driver. For this
reason, industry and academia have put forward efforts to enhanching cars with \acrfull{ad}
capabilities.
By \textbf{empowering humans} with autonomous vehicles, it is expected that traffic efficiency will
rise, and road fataility will fall.

\paragraph{Due to the critical safety situation of manuevering a car} in a public setting where other external
actors are present, it is essential that \acrlong{ads} are thoroughly tested before they are
deployed so that they are confirmed to be sufficiently safe and capable of handle the situations
they may typically end up in.
But due to the complicated nature of the typical \acrshort{ad} operating environment, coming up with
exhaustive system test solutions is near impossible.
For this reason we want a way of testing the system that is capable of pushing the \acrlong{ad} to
its limits such that we can measure its performance and see if it is capable of
handling complex scenarios.

\paragraph{Having an existing repository of \acrlong{ad} test cases,} such as
DeepScenario we wish to improve them. \textbf{\acrfull{llms}} have demonstrated
great capabilities of in  context learning and emergent  abilities, which begs
the question of their  applicabilty for \acrshort{ad} testing.  There are
various methods of testing  \acrlong{ads}. Can these existing tests methods be
improved by applying \acrshort{llm} technology to them?

% Yet, testing is \textit{important} for \acrlong{ads}, and text case generation is costly. We
% therefore pose the question: Can \acrshort{llms} be applied for (1) lowering the
% cost of testing, and (2) increasing the thouroughness of \acrlong{ads} testing?
