@inproceedings{adsComplexityIndex18,
  author    = {Park, Youngseok and Yang, Ji Hyun and Lim, Sejoon},
  booktitle = {2018 IEEE International Conference on Systems, Man, and Cybernetics (SMC)},
  title     = {Development of Complexity Index and Predictions of Accident Risks for Mixed Autonomous Driving Levels},
  year      = {2018},
  volume    = {},
  number    = {},
  pages     = {1181-1188},
  keywords  = {Autonomous vehicles;Complexity theory;Roads;Accidents;Standards;Indexes;Vehicle-to-everything;complexity of driving situation;autonomous vehicle;mixed autonomous driving levels;PreScan simulator;perplexity},
  doi       = {10.1109/SMC.2018.00208}
}

@inproceedings{ADTestingReview16,
  title        = {Autonomous vehicles testing methods review},
  author       = {Huang, WuLing and Wang, Kunfeng and Lv, Yisheng and Zhu, FengHua},
  booktitle    = {2016 IEEE 19th International Conference on Intelligent Transportation Systems (ITSC)},
  pages        = {163--168},
  year         = {2016},
  organization = {IEEE}
}

@inproceedings{airsim,
  author    = {Shital Shah and Debadeepta Dey and Chris Lovett and Ashish Kapoor},
  title     = {AirSim: High-Fidelity Visual and Physical Simulation for Autonomous Vehicles},
  year      = {2017},
  booktitle = {Field and Service Robotics},
  eprint    = {arXiv:1705.05065},
  url       = {https://arxiv.org/abs/1705.05065}
}

@article{anderson1972more,
  title     = {More Is Different: Broken symmetry and the nature of the hierarchical structure of science.},
  author    = {Anderson, Philip W},
  journal   = {Science},
  volume    = {177},
  number    = {4047},
  pages     = {393--396},
  year      = {1972},
  publisher = {American Association for the Advancement of Science}
}
@inproceedings{attentionIsAllYouNeed,
  author    = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, \L{}ukasz and Polosukhin, Illia},
  title     = {Attention is all you need},
  year      = {2017},
  isbn      = {9781510860964},
  publisher = {Curran Associates Inc.},
  address   = {Red Hook, NY, USA},
  abstract  = {The dominant sequence transduction models are based on complex recurrent or convolutional neural networks that include an encoder and a decoder. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.0 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature.},
  booktitle = {Proceedings of the 31st International Conference on Neural Information Processing Systems},
  pages     = {6000–6010},
  numpages  = {11},
  location  = {Long Beach, California, USA},
  series    = {NIPS'17}
}
@inproceedings{autoSceneGen,
  title     = {Generating Traffic Scenarios via In-Context Learning to Learn Better Motion Planner},
  author    = {Aiersilan, Aizierjiang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  volume    = {39},
  number    = {14},
  pages     = {14539--14547},
  year      = {2025},
  doi       = {10.1609/aaai.v39i14.33593}
}
@misc{bertPaper,
  title         = {BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  author        = {Jacob Devlin and Ming-Wei Chang and Kenton Lee and Kristina Toutanova},
  year          = {2019},
  eprint        = {1810.04805},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/1810.04805}
}
@inproceedings{Carla,
  title     = { {CARLA}: {An} Open Urban Driving Simulator},
  author    = {Alexey Dosovitskiy and German Ros and Felipe Codevilla and Antonio Lopez and Vladlen Koltun},
  booktitle = {Proceedings of the 1st Annual Conference on Robot Learning},
  pages     = {1--16},
  year      = {2017}
}

@inproceedings{chat2Scenario,
  author    = {Zhao, Yongqi and Xiao, Wenbo and Mihalj, Tomislav and Hu, Jia and Eichberger, Arno},
  booktitle = {2024 IEEE Intelligent Vehicles Symposium (IV)},
  title     = {Chat2Scenario: Scenario Extraction From Dataset Through Utilization of Large Language Model},
  year      = {2024},
  volume    = {},
  number    = {},
  pages     = {559-566},
  keywords  = {Measurement;Intelligent vehicles;Large language models;Natural language processing;Testing;Large Language Model;Scenario Extraction;Automated Driving Systems;Virtual Testing},
  doi       = {10.1109/IV55156.2024.10588843}
}
@inproceedings{commonRoadOG,
  author    = {Althoff, Matthias and Koschi, Markus and Manzinger, Stefanie},
  booktitle = {2017 IEEE Intelligent Vehicles Symposium (IV)},
  title     = {CommonRoad: Composable benchmarks for motion planning on roads},
  year      = {2017},
  volume    = {},
  number    = {},
  pages     = {719-726},
  keywords  = {Benchmark testing;Planning;Mathematical model;Cost function;Libraries;Vehicle dynamics;Roads},
  doi       = {10.1109/IVS.2017.7995802}
}
@article{conceptBlending,
  author  = {Fauconnier, Gilles and Turner, Mark},
  year    = {2003},
  month   = {03},
  pages   = {},
  title   = {Conceptual Blending, Form and Meaning},
  volume  = {19},
  journal = {Recherches en Communication; No 19: Sémiotique cognitive — Cognitive Semiotics; 57-86},
  doi     = {10.14428/rec.v19i19.48413}
}

@inproceedings{convOpenScenarioToCR,
  author    = {Lin, Yuanfei and Ratzel, Michael and Althoff, Matthias},
  booktitle = {2023 IEEE 26th International Conference on Intelligent Transportation Systems (ITSC)},
  title     = {Automatic Traffic Scenario Conversion from OpenSCENARIO to CommonRoad},
  year      = {2023},
  volume    = {},
  number    = {},
  pages     = {4941-4946},
  keywords  = {Terminology;Trajectory;Safety;Planning;Vehicle dynamics;Autonomous vehicles;Testing},
  doi       = {10.1109/ITSC57777.2023.10422422}
}

% TODO: Burde se over at denne blir riktig i outputen
@dataset{CriticalScenarios,
  author    = {Crespo Rodriguez, Victor and
               Neelofar and
               Aleti, Aldeida},
  title     = {{Instance Space Analysis of Testing of Autonomous 
               Vehicles in Critical Scenarios}},
  month     = may,
  year      = 2024,
  publisher = {Zenodo},
  version   = 1,
  doi       = {10.5281/zenodo.11202385},
  url       = {https://doi.org/10.5281/zenodo.11202385}
}


@article{deepCollision,
  author   = {Lu, Chengjie and Shi, Yize and Zhang, Huihui and Zhang, Man and Wang, Tiexin and Yue, Tao and Ali, Shaukat},
  journal  = {IEEE Transactions on Software Engineering},
  title    = {Learning Configurations of Operating Environment of Autonomous Vehicles to Maximize their Collisions},
  year     = {2023},
  volume   = {49},
  number   = {1},
  pages    = {384-402},
  keywords = {Autonomous vehicles;Testing;Roads;Vehicle dynamics;Space vehicles;Q-learning;Uncertainty;Autonomous vehicle testing;reinforcement learning;environment configuration},
  doi      = {10.1109/TSE.2022.3150788}
}

@article{DeepScenario,
  author  = {Chengjie Lu and Tao Yue and Shaukat Ali},
  title   = {DeepScenario: An Open Driving Scenario Dataset for Autonomous Driving System Testing},
  journal = {IEEE/ACM 20th International Conference on Mining Software Repositories (MSR)},
  year    = {2023},
  pages   = {52--56}
}

@inproceedings{driveAsYouSpeak,
  author    = {Cui, Can and Ma, Yunsheng and Cao, Xu and Ye, Wenqian and Wang, Ziran},
  title     = {Drive As You Speak: Enabling Human-Like Interaction With Large Language Models in Autonomous Vehicles},
  booktitle = {Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV) Workshops},
  month     = {1},
  year      = {2024},
  pages     = {902-909}
}

@inproceedings{egoDefinition,
  title        = {Coverage Metrics for a Scenario Database for the Scenario-Based Assessment of Automated Driving Systems},
  author       = {de Gelder, Erwin and Buermann, Maren and Den Camp, Olaf Op},
  booktitle    = {2024 IEEE International Automated Vehicle Validation Conference (IAVVC)},
  pages        = {1--8},
  year         = {2024},
  organization = {IEEE}
}


@misc{emergentabilitiesLLM,
  title         = {Emergent Abilities of Large Language Models},
  author        = {Jason Wei and Yi Tay and Rishi Bommasani and Colin Raffel and Barret Zoph and Sebastian Borgeaud and Dani Yogatama and Maarten Bosma and Denny Zhou and Donald Metzler and Ed H. Chi and Tatsunori Hashimoto and Oriol Vinyals and Percy Liang and Jeff Dean and William Fedus},
  year          = {2022},
  eprint        = {2206.07682},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2206.07682}
}

@inproceedings{generatingOpenScenario,
  author    = {Chen, He and Ren, Hongpinng and Li, Rui and Yang, Guang and Ma, Shanshan},
  booktitle = {2022 9th International Conference on Dependable Systems and Their Applications (DSA)},
  title     = {Generating Autonomous Driving Test Scenarios based on OpenSCENARIO},
  year      = {2022},
  volume    = {},
  number    = {},
  pages     = {650-658},
  keywords  = {Costs;Roads;Writing;Safety;Autonomous vehicles;Meteorology;autonomous driving;simulation test;OpenSCENARIO;test scenario;batch SCENARIO generation},
  doi       = {10.1109/DSA56465.2022.00093}
}



@article{go,
  title     = {The go programming language},
  author    = {Meyerson, Jeff},
  journal   = {IEEE software},
  volume    = {31},
  number    = {5},
  pages     = {100--104},
  year      = {2014},
  publisher = {IEEE}
}

@misc{goldberg2015primerneuralnetworkmodels,
  title         = {A Primer on Neural Network Models for Natural Language Processing},
  author        = {Yoav Goldberg},
  year          = {2015},
  eprint        = {1510.00726},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/1510.00726}
}

@misc{hungryLlm,
  title         = {How Hungry is AI? Benchmarking Energy, Water, and Carbon Footprint of LLM Inference},
  author        = {Nidhal Jegham and Marwen Abdelatti and Lassad Elmoubarki and Abdeltawab Hendawi},
  year          = {2025},
  eprint        = {2505.09598},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CY},
  url           = {https://arxiv.org/abs/2505.09598}
}

@book{jm,
  author  = {Daniel Jurafsky and James H. Martin},
  title   = {Speech and Language Processing: An Introduction to
             Natural Language Processing, Computational Linguistics,
             and Speech Recognition with Language Models},
  year    = {2025},
  url     = {https://web.stanford.edu/~jurafsky/slp3/},
  note    = {Online manuscript released January 12, 2025},
  edition = {3rd}
}

@incollection{kamath2024llm,
  title     = {LLM Adaptation and Utilization},
  author    = {Kamath, Uday and Keenan, Kevin and Somers, Garrett and Sorenson, Sarah},
  booktitle = {Large Language Models: A Deep Dive: Bridging Theory and Practice},
  pages     = {135--175},
  year      = {2024},
  publisher = {Springer}
}

@misc{kittiCarla,
  title         = {KITTI-CARLA: a KITTI-like dataset generated by CARLA Simulator},
  author        = {Jean-Emmanuel Deschaud},
  year          = {2021},
  eprint        = {2109.00892},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV},
  url           = {https://arxiv.org/abs/2109.00892}
}

@misc{languageconditionedtrafficgeneration,
  title         = {Language Conditioned Traffic Generation},
  author        = {Shuhan Tan and Boris Ivanovic and Xinshuo Weng and Marco Pavone and Philipp Kraehenbuehl},
  year          = {2023},
  eprint        = {2307.07947},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV},
  url           = {https://arxiv.org/abs/2307.07947}
}

@article{lgsvl,
  title   = {LGSVL Simulator: A High Fidelity Simulator for Autonomous Driving},
  author  = {Rong, Guodong and Shin, Byung Hyun and Tabatabaee, Hadi and Lu, Qiang and Lemke, Steve and Mo{\v{z}}eiko, M{\=a}rti{\c{n}}{\v{s}} and Boise, Eric and Uhm, Geehoon and Gerow, Mark and Mehta, Shalin and others},
  journal = {arXiv preprint arXiv:2005.03778},
  year    = {2020}
}

@misc{LLM4AD,
  title         = {Large Language Models for Autonomous Driving (LLM4AD): Concept, Benchmark, Experiments, and Challenges},
  author        = {Can Cui and Yunsheng Ma and Zichong Yang and Yupeng Zhou and Peiran Liu and Juanwu Lu and Lingxi Li and Yaobin Chen and Jitesh H. Panchal and Amr Abdelraouf and Rohit Gupta and Kyungtae Han and Ziran Wang},
  year          = {2025},
  eprint        = {2410.15281},
  archiveprefix = {arXiv},
  primaryclass  = {cs.RO},
  url           = {https://arxiv.org/abs/2410.15281}
}


@article{llmCarbon,
  title     = {The carbon emissions of writing and illustrating are lower for AI than for humans},
  author    = {Tomlinson, Bill and Black, Rebecca W and Patterson, Donald J and Torrance, Andrew W},
  journal   = {Scientific Reports},
  volume    = {14},
  number    = {1},
  pages     = {3732},
  year      = {2024},
  publisher = {Nature Publishing Group UK London}
}

@inproceedings{LLMDrivenTestingADS24,
  author    = {Petrovic, Nenad and Lebioda, Krzysztof and Zolfaghari, Vahid and Schamschurko, André and Kirchner, Sven and Purschke, Nils and Pan, Fengjunjie and Knoll, Alois},
  booktitle = {2024 2nd International Conference on Foundation and Large Language Models (FLLM)},
  title     = {LLM-Driven Testing for Autonomous Driving Scenarios},
  year      = {2024},
  volume    = {},
  number    = {},
  pages     = {173-178},
  keywords  = {Codes;Large language models;Prototypes;Transformers;Cognitive load;Test pattern generators;Autonomous vehicles;Testing;Load modeling;Automotive engineering;autonomous driving;CARLA;Generative Pre-Trained Transformer (GPT);Large Language Model (LLM);Llama3;Model-Driven Engineering (MDE)},
  doi       = {10.1109/FLLM63129.2024.10852505}
}

@article{LLMScenarioChang24,
  author   = {Chang, Cheng and Wang, Siqi and Zhang, Jiawei and Ge, Jingwei and Li, Li},
  journal  = {IEEE Transactions on Systems, Man, and Cybernetics: Systems},
  title    = {LLMScenario: Large Language Model Driven Scenario Generation},
  year     = {2024},
  volume   = {54},
  number   = {11},
  pages    = {6581-6594},
  keywords = {Scenario generation;Cognition;Autonomous vehicles;Tuning;Testing;Semantics;Task analysis;Large language model (LLM);scenario engineering;scenario generation},
  doi      = {10.1109/TSMC.2024.3392930}
}

@misc{llmSurvey,
  title         = {A Survey of Large Language Models},
  author        = {Wayne Xin Zhao and Kun Zhou and Junyi Li and Tianyi Tang and Xiaolei Wang and Yupeng Hou and Yingqian Min and Beichen Zhang and Junjie Zhang and Zican Dong and Yifan Du and Chen Yang and Yushuo Chen and Zhipeng Chen and Jinhao Jiang and Ruiyang Ren and Yifan Li and Xinyu Tang and Zikang Liu and Peiyu Liu and Jian-Yun Nie and Ji-Rong Wen},
  year          = {2025},
  eprint        = {2303.18223},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2303.18223}
}
@article{luo2024semievol,
  title   = {SemiEvol: Semi-supervised Fine-tuning for LLM Adaptation},
  author  = {Luo, Junyu and Luo, Xiao and Chen, Xiusi and Xiao, Zhiping and Ju, Wei and Zhang, Ming},
  journal = {arXiv preprint arXiv:2410.14745},
  year    = {2024}
}

@book{marsland,
  added-at  = {2014-06-02T22:49:10.000+0200},
  author    = {Marsland, Stephen},
  biburl    = {https://www.bibsonomy.org/bibtex/28808fc9257c5b5216873086c646da37c/hpschu},
  ee        = {http://www.crcpress.com/product/isbn/9781420067187},
  interhash = {11e7f27e7583e5c1e46fc191ab146919},
  intrahash = {8808fc9257c5b5216873086c646da37c},
  isbn      = {978-1-4200-6718-7},
  keywords  = {learning machine},
  pages     = {I-XVI, 1-390},
  publisher = {CRC Press},
  series    = {Chapman and Hall / CRC machine learning and pattern recognition series},
  timestamp = {2014-06-02T22:49:10.000+0200},
  title     = {Machine Learning - An Algorithmic Perspective.},
  edition   = {2nd},
  year      = 2015
}



@inproceedings{numba,
  title     = {Numba: A llvm-based python jit compiler},
  author    = {Lam, Siu Kwan and Pitrou, Antoine and Seibert, Stanley},
  booktitle = {Proceedings of the Second Workshop on the LLVM Compiler Infrastructure in HPC},
  pages     = {1--6},
  year      = {2015}
}



@inproceedings{parrot,
  author    = {Bender, Emily M. and Gebru, Timnit and McMillan-Major, Angelina and Shmitchell, Shmargaret},
  title     = {On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?},
  year      = {2021},
  isbn      = {9781450383097},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3442188.3445922},
  doi       = {10.1145/3442188.3445922},
  abstract  = {The past 3 years of work in NLP have been characterized by the development and deployment of ever larger language models, especially for English. BERT, its variants, GPT-2/3, and others, most recently Switch-C, have pushed the boundaries of the possible both through architectural innovations and through sheer size. Using these pretrained models and the methodology of fine-tuning them for specific tasks, researchers have extended the state of the art on a wide array of tasks as measured by leaderboards on specific benchmarks for English. In this paper, we take a step back and ask: How big is too big? What are the possible risks associated with this technology and what paths are available for mitigating those risks? We provide recommendations including weighing the environmental and financial costs first, investing resources into curating and carefully documenting datasets rather than ingesting everything on the web, carrying out pre-development exercises evaluating how the planned approach fits into research and development goals and supports stakeholder values, and encouraging research directions beyond ever larger language models.},
  booktitle = {Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency},
  pages     = {610–623},
  numpages  = {14},
  location  = {Virtual Event, Canada},
  series    = {FAccT '21}
}


@article{promptingSurvey,
  author     = {Liu, Pengfei and Yuan, Weizhe and Fu, Jinlan and Jiang, Zhengbao and Hayashi, Hiroaki and Neubig, Graham},
  title      = {Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing},
  year       = {2023},
  issue_date = {September 2023},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {55},
  number     = {9},
  issn       = {0360-0300},
  url        = {https://doi.org/10.1145/3560815},
  doi        = {10.1145/3560815},
  abstract   = {This article surveys and organizes research works in a new paradigm in natural language processing, which we dub “prompt-based learning.” Unlike traditional supervised learning, which trains a model to take in an input x and predict an output y as P(y|x), prompt-based learning is based on language models that model the probability of text directly. To use these models to perform prediction tasks, the original input x is modified using a template into a textual string prompt x′ that has some unfilled slots, and then the language model is used to probabilistically fill the unfilled information to obtain a final string x̂, from which the final output y can be derived. This framework is powerful and attractive for a number of reasons: It allows the language model to be pre-trained on massive amounts of raw text, and by defining a new prompting function the model is able to perform few-shot or even zero-shot learning, adapting to new scenarios with few or no labeled data. In this article, we introduce the basics of this promising paradigm, describe a unified set of mathematical notations that can cover a wide variety of existing work, and organize existing work along several dimensions, e.g.,&nbsp;the choice of pre-trained language models, prompts, and tuning strategies. To make the field more accessible to interested beginners, we not only make a systematic review of existing works and a highly structured typology of prompt-based concepts but also release other resources, e.g., a website  including constantly updated survey and paperlist.},
  journal    = {ACM Comput. Surv.},
  month      = jan,
  articleno  = {195},
  numpages   = {35},
  keywords   = {Pre-trained language models, prompting}
}

@misc{requirementsAllYouNeed,
  title         = {Are requirements really all you need? A case study of LLM-driven configuration code generation for automotive simulations},
  author        = {Krzysztof Lebioda and Nenad Petrovic and Fengjunjie Pan and Vahid Zolfaghari and Andre Schamschurko and Alois Knoll},
  year          = {2025},
  eprint        = {2505.13263},
  archiveprefix = {arXiv},
  primaryclass  = {cs.SE},
  url           = {https://arxiv.org/abs/2505.13263}
}

@inproceedings{RTCM,
  author    = {Yue, Tao and Ali, Shaukat and Zhang, Man},
  title     = {RTCM: a natural language based, automated, and practical test case generation framework},
  year      = {2015},
  isbn      = {9781450336208},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/2771783.2771799},
  doi       = {10.1145/2771783.2771799},
  abstract  = {Based on our experience of collaborating with industry, we observed that test case generation usually relies on test case specifications (TCSs), commonly written in natural language, specifying test cases of a System Under Test at a high level of abstraction. In practice, TCSs are commonly used by test engineers as reference documents to perform these activities: 1) Manually executing test cases in TCSs; 2) Manually coding test cases in a test scripting language for automated test case execution. In the latter case, the gap between TCSs and executable test cases has to be filled by test engineers, requiring a significant amount of coding effort and domain knowledge. Motivated by the above observations from the industry, we first propose, in this paper, a TCS language, named as Restricted Test Case Modeling (RTCM), which is based on natural language and composed of an easy-to-use template, a set of restriction rules and keywords. Second, we propose a test case generation tool (aToucan4Test), which takes TCSs in RTCM as input and generates either manual test cases or automatically executable test cases, based on various coverage criteria defined on RTCM. To assess the applicability of RTCM, we manually modeled two industrial case studies and examined 30 automatically generated TCSs. To evaluate aToucan4Test, we modeled three subsystems of a Video Conferencing System developed by Cisco Systems, Norway and automatically generated executable test cases. These test cases were successfully executed on two commercial software versions. In the paper, we also discuss our experience of applying RTCM and aToucan4Test in an industrial context and compare our approach with other model-based testing methodologies.},
  booktitle = {Proceedings of the 2015 International Symposium on Software Testing and Analysis},
  pages     = {397–408},
  numpages  = {12},
  keywords  = {Test Case Specification, Test Case Generation, RUCM, Model},
  location  = {Baltimore, MD, USA},
  series    = {ISSTA 2015}
}

@article{safeToDrive,
  title     = {Is it safe to drive? An overview of factors, metrics, and datasets for driveability assessment in autonomous driving},
  author    = {Guo, Junyao and Kurup, Unmesh and Shah, Mohak},
  journal   = {IEEE Transactions on Intelligent Transportation Systems},
  volume    = {21},
  number    = {8},
  pages     = {3135--3151},
  year      = {2019},
  publisher = {IEEE}
}

@article{sapirWhorf,
  title   = {Reference in memorial tribute to Eric Lenneberg},
  journal = {Cognition},
  volume  = {4},
  number  = {2},
  pages   = {125-153},
  year    = {1976},
  issn    = {0010-0277},
  doi     = {https://doi.org/10.1016/0010-0277(76)90001-9},
  url     = {https://www.sciencedirect.com/science/article/pii/0010027776900019},
  author  = {Roger Brown}
}


@inproceedings{scenarioTysk,
  author    = {Wershofen, Klaus Peter
               and Graefe, Volker},
  editor    = {Schmidt, G{\"u}nther
               and Freyberger, Franz},
  title     = {Situationserkennung als Grundlage der Verhaltenssteuerung eines mobilen Roboters},
  booktitle = {Autonome Mobile Systeme 1996},
  year      = {1996},
  publisher = {Springer Berlin Heidelberg},
  address   = {Berlin, Heidelberg},
  pages     = {170--179},
  abstract  = {Ein neuartiges Systemkonzept f{\"u}r verhaltensbasierte mobile Roboter, die objektorientierte verhaltensbasierte Navigation, wird vorgestellt. Kernpunkt dabei ist, da{\ss} die Verhaltensauswahl situationsgesteuert erfolgt. Der hierf{\"u}r ma{\ss}gebliche Situationsbegriff wird erl{\"a}utert; er ergibt sich im wesentlichen aus den Zust{\"a}nden der in der Umgebung des Roboters befindlichen k{\"o}rperlichen Objekte und des Roboters selbst. Voraussetzungen f{\"u}r eine Realisierung des Konzepts sind eine leistungsf{\"a}hige Sensorik und eine angepa{\ss}te Wissensrepr{\"a}sentation. Ein globales Koordinatensystem und eine genaue Kenntnis der geometrischen Gegebenheiten des Einsatzgebiets des Roboters sind dagegen nicht erforderlich.},
  isbn      = {978-3-642-80324-6}
}


@inproceedings{scenes,
  author    = {Ulbrich, Simon and Menzel, Till and Reschka, Andreas and Schuldt, Fabian and Maurer, Markus},
  booktitle = {2015 IEEE 18th International Conference on Intelligent Transportation Systems},
  title     = {Defining and Substantiating the Terms Scene, Situation, and Scenario for Automated Driving},
  year      = {2015},
  volume    = {},
  number    = {},
  pages     = {982-988},
  keywords  = {Vehicles;Observers;Context modeling;Planning;Vehicle dynamics;Roads;Systems architecture},
  doi       = {10.1109/ITSC.2015.164}
}


@inproceedings{schmidtScenario,
  author    = {Schmidt, Max Theo and Hofmann, Ulrich and Bouzouraa, M. Essayed},
  booktitle = {17th International IEEE Conference on Intelligent Transportation Systems (ITSC)},
  title     = {A novel goal oriented concept for situation representation for ADAS and automated driving},
  year      = {2014},
  volume    = {},
  number    = {},
  pages     = {886-893},
  keywords  = {Vehicles;Surface acoustic waves;Automation;Communities;Sensors;Uncertainty;Decision making},
  doi       = {10.1109/ITSC.2014.6957801}
}


@article{seGpt,
  author   = {Li, Xuan and Liu, Enlu and Shen, Tianyu and Huang, Jun and Wang, Fei-Yue},
  journal  = {IEEE Transactions on Intelligent Vehicles},
  title    = {ChatGPT-Based Scenario Engineer: A New Framework on Scenario Generation for Trajectory Prediction},
  year     = {2024},
  volume   = {9},
  number   = {3},
  pages    = {4422-4431},
  keywords = {Scenario generation;Trajectory;Testing;Transformers;Numerical models;Autonomous vehicles;Task analysis;Parallel driving;scenarios engineering;foundation model;vehicle operating system;generative pre-trained transformer;trajectory prediction},
  doi      = {10.1109/TIV.2024.3363232}
}

@inproceedings{sproutGreenLlm,
  title     = {Sprout: Green Generative {AI} with Carbon-Efficient {LLM} Inference},
  author    = {Li, Baolin  and
               Jiang, Yankai  and
               Gadepally, Vijay  and
               Tiwari, Devesh},
  editor    = {Al-Onaizan, Yaser  and
               Bansal, Mohit  and
               Chen, Yun-Nung},
  booktitle = {Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing},
  month     = nov,
  year      = {2024},
  address   = {Miami, Florida, USA},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2024.emnlp-main.1215/},
  doi       = {10.18653/v1/2024.emnlp-main.1215},
  pages     = {21799--21813},
  abstract  = {The rapid advancement of generative AI has heightened environmental concerns, particularly regarding carbon emissions. Our framework, Sprout, addresses these challenges by reducing the carbon footprint of inference in large language models (LLMs). Sprout introduces ``generation directives'' to guide the autoregressive generation process, achieving a balance between ecological sustainability and high-quality outputs. By employing a strategic optimizer for directive assignment and a novel offline quality evaluator, Sprout reduces the carbon footprint of generative LLM inference by over 40{\%} in real-world evaluations, using the Llama model and global electricity grid data. This work is crucial as the rising interest in inference time compute scaling laws amplifies environmental concerns, emphasizing the need for eco-friendly AI solutions.}
}

@misc{surveyLLMScenarioBasedTesting,
  title         = {A Survey on the Application of Large Language Models in Scenario-Based Testing of Automated Driving Systems},
  author        = {Yongqi Zhao and Ji Zhou and Dong Bi and Tomislav Mihalj and Jia Hu and Arno Eichberger},
  year          = {2025},
  eprint        = {2505.16587},
  archiveprefix = {arXiv},
  primaryclass  = {cs.SE},
  url           = {https://arxiv.org/abs/2505.16587}
}


@inproceedings{sustainableLlmServing,
  author    = {Ding, Yi and Shi, Tianyao},
  booktitle = {2024 IEEE 15th International Green and Sustainable Computing Conference (IGSC)},
  title     = {Sustainable LLM Serving: Environmental Implications, Challenges, and Opportunities : Invited Paper},
  year      = {2024},
  volume    = {},
  number    = {},
  pages     = {37-38},
  keywords  = {Training;Energy consumption;Accuracy;Large language models;Natural languages;Green products;Carbon footprint},
  doi       = {10.1109/IGSC64514.2024.00016}
}

@inproceedings{testCoverage94,
  author    = {Malaiya, Y.K. and Naixin Li and Bieman, J. and Karcich, R. and Skibbe, B.},
  booktitle = {Proceedings of 1994 IEEE International Symposium on Software Reliability Engineering},
  title     = {The relationship between test coverage and reliability},
  year      = {1994},
  volume    = {},
  number    = {},
  pages     = {186-195},
  keywords  = {System testing;Space technology;Automatic testing;Software testing;Predictive models;Computer science;Automatic control;Application software;Software systems;Software measurement},
  doi       = {10.1109/ISSRE.1994.341373}
}

@misc{thirstyLlm,
  title         = {Making AI Less "Thirsty": Uncovering and Addressing the Secret Water Footprint of AI Models},
  author        = {Pengfei Li and Jianyi Yang and Mohammad A. Islam and Shaolei Ren},
  year          = {2025},
  eprint        = {2304.03271},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  url           = {https://arxiv.org/abs/2304.03271}
}


@software{unrealengine,
  author  = {{Epic Games}},
  title   = {Unreal Engine},
  url     = {https://www.unrealengine.com},
  version = {4.22.1},
  date    = {2019-04-25}
}

@article{v2xTestingSurvey2019,
  author         = {Wang, Jian and Shao, Yameng and Ge, Yuming and Yu, Rundong},
  title          = {A Survey of Vehicle to Everything (V2X) Testing},
  journal        = {Sensors},
  volume         = {19},
  year           = {2019},
  number         = {2},
  article-number = {334},
  url            = {https://www.mdpi.com/1424-8220/19/2/334},
  pubmedid       = {30650658},
  issn           = {1424-8220},
  abstract       = {Vehicle to everything (V2X) is a new generation of information and communication technologies that connect vehicles to everything. It not only creates a more comfortable and safer transportation environment, but also has much significance for improving traffic efficiency, and reducing pollution and accident rates. At present, the technology is still in the exploratory stage, and the problems of traffic safety and information security brought about by V2X applications have not yet been fully evaluated. Prior to marketization, we must ensure the reliability and maturity of the technology, which must be rigorously tested and verified. Therefore, testing is an important part of V2X technology. This article focuses on the V2X application requirements and its challenges, the need of testing. Then we also investigate and summarize the testing methods for V2X in the communication process and describe them in detail from the architectural perspective. In addition, we have proposed an end-to-end testing system combining virtual and real environments which can undertake the test task of the full protocol stack.},
  doi            = {10.3390/s19020334}
}

@article{watson2005autonomous,
  title   = {Autonomous systems},
  author  = {Watson, David P and Scheidt, David H},
  journal = {Johns Hopkins APL technical digest},
  volume  = {26},
  number  = {4},
  pages   = {368--376},
  year    = {2005}
}

@article{Chen2025,
  author   = {Chen, Zhengxian
              and Liu, Yuqi
              and Ni, Wenjie
              and Hai, Han
              and Huang, Chaosheng
              and Xu, Boyang
              and Ling, Zihan
              and Shen, Yang
              and Yu, Wenhao
              and Wang, Huanan
              and Li, Jun},
  title    = {Predicting driving comfort in autonomous vehicles using road information and multi-head attention models},
  journal  = {Nature Communications},
  year     = {2025},
  month    = {Mar},
  day      = {19},
  volume   = {16},
  number   = {1},
  pages    = {2709},
  abstract = {Driving comfort is a crucial consideration in the automotive industry. In the realm of autonomous driving, comfort has always been a factor that requires continuous improvement. A common approach to improving driving comfort is through the optimization of local path planning. Nevertheless, it is imperative to recognize that macroscopic factors, including traffic flow and road conditions, wield a substantial influence on comfort. For instance, complex traffic scenarios increase the possibility of emergency braking, thereby affecting comfort. Consequently, investigating the intricate interplay between comfort and global path planning becomes essential. This paper introduces a methodology and framework for predicting driving comfort by leveraging road information. The study established a road information-driving comfort dataset and devised prediction models using multi-head attention mechanism. The ensuing discussion elucidates the practical application of the model in path planning through examples and tests. Following the path optimized by the model, the vehicles exhibited a reduction in jerk. This research predicted driving comfort based on road information and integrated it with global path planning, which holds significant implications for autonomous driving navigation systems and provides a valuable reference for related research.},
  issn     = {2041-1723},
  doi      = {10.1038/s41467-025-57845-z},
  url      = {https://doi.org/10.1038/s41467-025-57845-z}
}


@inproceedings{RealityBites,
  author    = {Wu, Jiahui and Lu, Chengjie and Arrieta, Aitor and Yue, Tao and Ali, Shaukat},
  title     = {Reality Bites: Assessing the Realism of Driving Scenarios with Large Language Models},
  year      = {2024},
  isbn      = {9798400706097},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3650105.3652296},
  doi       = {10.1145/3650105.3652296},
  abstract  = {Large Language Models (LLMs) are demonstrating outstanding potential for tasks such as text generation, summarization, and classification. Given that such models are trained on a humongous amount of online knowledge, we hypothesize that LLMs can assess whether driving scenarios generated by autonomous driving testing techniques are realistic, i.e., being aligned with real-world driving conditions. To test this hypothesis, we conducted an empirical evaluation to assess whether LLMs are effective and robust in performing the task. This reality check is an important step towards devising LLM-based autonomous driving testing techniques. For our empirical evaluation, we selected 64 realistic scenarios from DeepScenario-an open driving scenario dataset. Next, by introducing minor changes to them, we created 512 additional realistic scenarios, to form an overall dataset of 576 scenarios. With this dataset, we evaluated three LLMs (GPT-3.5, Llama2-13B, and Mistral-7B) to assess their robustness in assessing the realism of driving scenarios. Our results show that: (1) Overall, GPT-3.5 achieved the highest robustness compared to Llama2-13B and Mistral-7B, consistently throughout almost all scenarios, roads, and weather conditions; (2) Mistral-7B performed the worst consistently; (3) Llama2-13B achieved good results under certain conditions; and (4) roads and weather conditions do influence the robustness of the LLMs.},
  booktitle = {Proceedings of the 2024 IEEE/ACM First International Conference on AI Foundation Models and Software Engineering},
  pages     = {40–51},
  numpages  = {12},
  keywords  = {large language models, realistic driving scenarios, robustness},
  location  = {Lisbon, Portugal},
  series    = {FORGE '24}
}

@article{fengJerk17,
  title    = {Can vehicle longitudinal jerk be used to identify aggressive drivers? An examination using naturalistic driving data},
  journal  = {Accident Analysis \& Prevention},
  volume   = {104},
  pages    = {125-136},
  year     = {2017},
  issn     = {0001-4575},
  doi      = {https://doi.org/10.1016/j.aap.2017.04.012},
  url      = {https://www.sciencedirect.com/science/article/pii/S0001457517301409},
  author   = {Fred Feng and Shan Bao and James R. Sayer and Carol Flannagan and Michael Manser and Robert Wunderlich},
  keywords = {Driver behavior, Aggressive driving, Jerk, Naturalistic driving study},
  abstract = {This paper investigated the characteristics of vehicle longitudinal jerk (change rate of acceleration with respect to time) by using vehicle sensor data from an existing naturalistic driving study. The main objective was to examine whether vehicle jerk contains useful information that could be potentially used to identify aggressive drivers. Initial investigation showed that there are unique characteristics of vehicle jerk in drivers’ gas and brake pedal operations. Thus two jerk-based metrics were examined: (1) driver’s frequency of using large positive jerk when pressing the gas pedal, and (2) driver’s frequency of using large negative jerk when pressing the brake pedal. To validate the performance of the two metrics, drivers were firstly divided into an aggressive group and a normal group using three classification methods (1) traveling at excessive speed (speeding), (2) following too closely to a front vehicle (tailgating), and (3) their association with crashes or near-crashes in the dataset. The results show that those aggressive drivers defined using any of the three methods above were associated with significantly higher values of the two jerk-based metrics. Between the two metrics the frequency of using large negative jerk seems to have better performance in identifying aggressive drivers. A sensitivity analysis shows the findings were largely consistent with varying parameters in the analysis. The potential applications of this work include developing quantitative surrogate safety measures to identify aggressive drivers and aggressive driving, which could be potentially used to, for example, provide real-time or post-ride performance feedback to the drivers, or warn the surrounding drivers or vehicles using the connected vehicle technologies.}
}
@article{girayPromptEngineering23,
  author   = {Giray, Louie},
  title    = {Prompt Engineering with ChatGPT: A Guide for Academic Writers},
  journal  = {Annals of Biomedical Engineering},
  year     = {2023},
  month    = {12},
  day      = {01},
  volume   = {51},
  number   = {12},
  pages    = {2629-2633},
  abstract = {Prompt engineering is a relatively new discipline that refers to the practice of developing and optimizing prompts to effectively utilize large language models, particularly in natural language processing tasks. However, not many writers and researchers are familiar about this discipline. Hence, in this paper, I aim to highlight the significance of prompt engineering for academic writers and researchers, particularly the fledgling, in the rapidly evolving world of artificial intelligence. I also discuss the concepts of prompt engineering, large language models, and the techniques and pitfalls of writing prompts. Here, I contend that by acquiring prompt engineering skills, academic writers can navigate the changing landscape and leverage large language models to enhance their writing process. As artificial intelligence continues to advance and penetrate the arena of academic writing, prompt engineering equips writers and researchers with the essential skills to effectively harness the power of language models. This enables them to confidently explore new opportunities, enhance their writing endeavors, and remain at the forefront of utilizing cutting-edge technologies in their academic pursuits.},
  issn     = {1573-9686},
  doi      = {10.1007/s10439-023-03272-4},
  url      = {https://doi.org/10.1007/s10439-023-03272-4}
}


@article{meincke2025overtale,
  author       = {Lennart Meincke and
                  Dan Shapiro and
                  Angela Duckworth and
                  Ethan R. Mollick and
                  Lilach Mollick and
                  Robert Cialdini},
  title        = {Call Me A Jerk: Persuading AI to Comply with Objectionable Requests},
  journal  = {The Wharton School Research Paper},
  year         = {2025},
  month        = {7},
  url          = {https://ssrn.com/abstract=5357179},
  doi          = {10.2139/ssrn.5357179}
}